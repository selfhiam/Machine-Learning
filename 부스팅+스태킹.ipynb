{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIiYOfFf66QcDRG79vof6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selfhiam/Machine-Learning-Homework/blob/main/%EB%B6%80%EC%8A%A4%ED%8C%85%2B%EC%8A%A4%ED%83%9C%ED%82%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 부스팅(Boosting)\n",
        "* 여러 개의 약한 학습기(Weak Learners)를 순차적으로 학습시켜, 각각의 예측을 결합하여 더 강력한 최종 모델을 만드는 기법\n",
        "* 초기 전체 데이터에 대한 학습을 진행. 이후 생성되는 학습기는 이전 학습기가 잘못 예측한 데이터에 대해 더 많은 가중치를 두고 학습을 진행.\n",
        "* 해당 과정을 반복하면서 모델은 점점 더 정확성이 높아짐"
      ],
      "metadata": {
        "id": "x8F5pUronNwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-1. 부스팅의 예제\n",
        "\n",
        "* AdaBoost\n",
        "    * 간단한 결정 트리를 기반으로 하여, 각각의 반복에서 데이터 포인트에 가중치를 적용.\n",
        "    * 잘못 분류된 데이터 포인트에 더 높은 가중치를 부여하고, 이를 바탕으로 새로운 학습기를 훈련.\n",
        "    * 해당 과정이 반복될수록 모델은 점점 더 복잡하고 정확해 진다.\n",
        "\n",
        "* XGBoost\n",
        "    * 기울기 부스팅(Gradient Boosting)의 한 형태로, 효율적인 계산과 높은 예측 성능을 자랑\n",
        "    * 각 단계에서 손실 함수의 기울기를 사용하여 모델을 업데이트\n",
        "    * 병렬처리, 트리 가지치기, 교차 검증 등의 기능을 포함함."
      ],
      "metadata": {
        "id": "or6z32QDoGAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-2. AdaBoost 예제"
      ],
      "metadata": {
        "id": "pokUxftypSfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# iris 데이터\n",
        "iris = load_iris()\n",
        "X, y  = iris.data, iris.target\n",
        "\n",
        "# 데이터를 교육용 train, 테스트용 test를 생성함.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)\n",
        "\n",
        "# AdaBoost 모델 생성\n",
        "# n_estimators는 사용할 약한 학습기의 수를 지정함.\n",
        "ada = AdaBoostClassifier(n_estimators=100, random_state=2024)\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "# 예측값 및 정확도 확인\n",
        "pred = ada.predict(X_test)\n",
        "print('정확도 : ', accuracy_score(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM4kV405qktt",
        "outputId": "64af7cc4-2e26-44db-8595-80dc334dcc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 :  0.8666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-3. XGBoost 예제"
      ],
      "metadata": {
        "id": "vKlkUqlRsQZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# iris 데이터\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 데이터를 교육용 train, 테스트용 test를 생성함.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)\n",
        "\n",
        "# XGBoost 모델 생성\n",
        "xgb_data = xgb.XGBClassifier()\n",
        "xgb_data.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 정확도 확인\n",
        "pred1 = xgb_data.predict(X_test)\n",
        "print(\"정확도 : \", accuracy_score(y_test, pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4FN-btxtJA2",
        "outputId": "b89e0bdf-c900-471c-c5ca-83f83e7231cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 :  0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 스태킹(Stac king)\n",
        "* 스태킹은 여러 가지 다른 모델을 조합하여 새로운 모델을 생성하는 기법.\n",
        "* 기본 모델(base models)의 예측 결과를 새로운 데이터 세트로 사용하여, 최종 결정을 내리는 메타 모델(meta-model)을 훈련.\n",
        "* 다양한 종류의 모델들이 초기 예측을 수행, 해당 예측들을 입력 데이터로 하여금 최종 모델이 최종 예측을 수행"
      ],
      "metadata": {
        "id": "03o2zuiQtr8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 스태킹의 예제\n",
        "* 기본 모델의 훈련\n",
        "    * 여러 다른 종류의 모델들을 별도로 훈련시킵니다. 해당 모델은 동일한 데이터 세트에 대해 학습을 수행하지만, 다른 접근 방식을 이용하여 훈련을 진행함.\n",
        "\n",
        "* 메타 모델의 훈련\n",
        "    * 기본 모델들의 예측을 새로운 '메타'데이터 세트로 사용하고, 이를 기반으로 메타 모델을 훈련함. 메타모델은 기본 모델들의 예측을 종합하여 최종 예측을 결정함.\n"
      ],
      "metadata": {
        "id": "aggrKdG4uVif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. 기본 모델의 훈련 예제\n",
        "* ex) 결정 트리, 랜덤 포레스트, 서포트 벡터 머신(SVM)을 사용하여 학습을 진행함."
      ],
      "metadata": {
        "id": "QXW8lkxexj74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터 로드 및 분할\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)\n",
        "\n",
        "des = DecisionTreeClassifier(random_state=2024)\n",
        "ran = RandomForestClassifier(random_state=2024)\n",
        "svm = SVC(random_state=2024)\n",
        "\n",
        "des.fit(X_train, y_train)\n",
        "ran.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "des_pred = des.predict(X_test)\n",
        "print(\"DecisionTree정확도 : \", accuracy_score(y_test, des_pred))\n",
        "\n",
        "ran_pred = ran.predict(X_test)\n",
        "print(\"RandomForest정확도 : \", accuracy_score(y_test, ran_pred))\n",
        "\n",
        "svm_pred = svm.predict(X_test)\n",
        "print(\"SVC정확도 : \", accuracy_score(y_test, svm_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3c2VR0kywUx",
        "outputId": "fecfb1fe-a494-4031-f42e-878d006d08a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTree정확도 :  0.8666666666666667\n",
            "RandomForest정확도 :  0.9\n",
            "SVC정확도 :  0.8666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-4. 메타 모델 예제"
      ],
      "metadata": {
        "id": "i9kUNuYBzwlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 기본 모델의 예측 결과를 새로운 특성으로 사용\n",
        "meta_X_train = np.column_stack([\n",
        "    des.predict(X_train),\n",
        "    ran.predict(X_train),\n",
        "    svm.predict(X_train)\n",
        "])\n",
        "\n",
        "# 메타 모델 정의 및 훈련\n",
        "meta_model = LogisticRegression(random_state=2024)\n",
        "meta_model.fit(meta_X_train, y_train)\n",
        "\n",
        "# 테스트 데이터에 대한 최종 예측\n",
        "meta_X_test = np.column_stack([\n",
        "    des.predict(X_test),\n",
        "    ran.predict(X_test),\n",
        "    svm.predict(X_test)\n",
        "])\n",
        "\n",
        "meta_pred = meta_model.predict(meta_X_test)\n",
        "print(\"meta 정확도 : \", accuracy_score(y_test, meta_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8C8foPu2bCX",
        "outputId": "cb3bf63f-89b8-497a-e632-f4c029997ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta 정확도 :  0.8666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcPVtzgH2sFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}